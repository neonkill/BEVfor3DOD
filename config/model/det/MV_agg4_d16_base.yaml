

_target_: model_module.model.detection.fullmodel.BaseBEVDepth

reduce_dim: 64 
downsample_factor: 4
dbound: [2.0, 58.0, 0.5]
is_train_depth: True
aug_conf: ${data.image}

backbone:
  _target_: model_module.model.detection.backbone.agg4_4toGAP_ConvNext_depth.Backbone
  seg_chs: [96, 192, 384, 768, 768, 768]
  reduce_dim: 64


voxel_pooling:
  _target_: model_module.model.detection.voxel_pooling_module.VoxelModule

  x_bound: [-51.2, 51.2, 0.8]
  y_bound: [-51.2, 51.2, 0.8]
  z_bound: [-5, 3, 8]
  d_bound: ${model.dbound}
  final_dim: [256, 704]
  output_channels: ${model.reduce_dim}
  downsample_factor : ${model.downsample_factor}
  

matching:
  _target_: model_module.model.detection.matching_fulldepth.Matching

  bev_embedding: 
    bev_height: ${data.bev.h}
    bev_width: ${data.bev.w}
    h_meters: ${data.bev.h_meters}
    w_meters: ${data.bev.w_meters}
    offset: ${data.bev.offset}
    resolution: 8         
    # generated bev feature's resolution. 
    # If you want to get 25x25 from cross_attn, resolution must be set 8

  b_res: 4               # kv's resolution. 
  image_height: ${data.image.h}
  image_width: ${data.image.w}
  dim: ${model.reduce_dim}
  heads: 4
  norm : 'LN'
  cross_attn:
    _target_: model_module.model.detection.matching_fulldepth.CrossAttention

    dim: ${model.reduce_dim}
    heads: ${model.matching.heads}
    qkv_bias: True


head:
  _target_: model_module.model.detection.bev_depth_head.BEVDepthHead

  bev_backbone_conf : 
    type : 'ResNet'
    in_channels : 80  #!
    depth : 18
    num_stages : 3
    strides : [1, 2, 2]
    dilations : [1, 1, 1]
    out_indices : [0, 1, 2]
    norm_eval : False
    base_channels : 160
  bev_neck_conf :
    type : 'SECONDFPN'
    in_channels : [80, 160, 320, 640]   #!
    upsample_strides : [1, 2, 4, 8]
    out_channels : [64, 64, 64, 64]
  tasks : [{'num_class': 1, 'class_names': ['car']},
          {'num_class': 2, 'class_names': ['truck', 'construction_vehicle']},
          {'num_class': 2, 'class_names': ['bus', 'trailer']},
          {'num_class': 1, 'class_names': ['barrier']},
          {'num_class': 2, 'class_names': ['motorcycle', 'bicycle']},
          {'num_class': 2, 'class_names': ['pedestrian', 'traffic_cone']}]
  common_heads : 
    reg : [2, 2]
    height : [1, 2]
    dim : [3, 2]
    rot : [2, 2]
    vel : [2, 2]
  bbox_coder :
    type : 'CenterPointBBoxCoder'
    post_center_range : [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
    max_num : 500
    score_threshold : 0.1
    out_size_factor : 4
    voxel_size : [0.2, 0.2, 8]
    pc_range : [-51.2, -51.2, -5, 51.2, 51.2, 3]
    code_size : 9
  train_cfg :
    point_cloud_range : [-51.2, -51.2, -5, 51.2, 51.2, 3]
    grid_size : [512, 512, 1]
    voxel_size : [0.2, 0.2, 8]
    out_size_factor : 4
    dense_reg : 1
    gaussian_overlap : 0.1
    max_objs : 500
    min_radius : 2
    code_weights : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
  test_cfg :
    post_center_limit_range : [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
    max_per_img : 500
    max_pool_nms : False
    min_radius : [4, 12, 10, 1, 0.85, 0.175]
    score_threshold : 0.1
    out_size_factor : 4
    voxel_size : [0.2, 0.2, 8]
    nms_type : 'circle'
    pre_max_size : 1000
    post_max_size : 83
    nms_thr : 0.2
  in_channels : 256  # Equal to bev_neck output_channels.
  loss_cls : 
    type : 'GaussianFocalLoss'
    reduction : 'mean'
  loss_bbox : 
    type : L1Loss
    reduction : 'mean'
    loss_weight : 0.25
  gaussian_overlap : 0.1
  min_radius : 2
  separate_head : {'type': 'SeparateHead', 'init_bias': -2.19, 'final_kernel': 3}