
_target_: model_module.model.segmentation.fullmodel_with_det_depth_seg_center.FullModel

reduce_dim: 64
outputs:
  bev: [0, 1]
norm : 'LN'

backbone:
  _target_: model_module.model.segmentation.backbones.agg4_4toGAP_ConvNext_depth.Backbone
  seg_chs: [96, 192, 384, 768, 768, 768]
  bev_chs: [96, 192, 384, 768, 768, 768]
  reduce_dim: ${model.reduce_dim}

q_generator:
  _target_: model_module.model.segmentation.matching_seperate.Matching

  bev_embedding: 
    bev_height: ${data.bev.h}
    bev_width: ${data.bev.w}
    h_meters: ${data.bev.h_meters}
    w_meters: ${data.bev.w_meters}
    offset: ${data.bev.offset}
    resolution: 8         
    # generated bev feature's resolution. 
    # If you want to get 25x25 from cross_attn, resolution must be set 8

  b_res: 4               # kv's resolution. 
  image_height: ${data.image.h}
  image_width: ${data.image.w}
  dim: ${model.reduce_dim}
  heads: 4
  norm : 'LN'
  cross_attn:
    _target_: model_module.model.segmentation.matching_seperate.CrossAttention

    dim: ${model.reduce_dim}
    heads: ${model.q_generator.heads}
    qkv_bias: True

det_head:
  _target_:  model_module.model.segmentation.detection_head.centerpoint_head.CenterpointHead
  # _partial_: True
  
  # head_conf: 
  tasks: [{'num_class': 1, 'class_names': ['car']},
          {'num_class': 2, 'class_names': ['truck', 'construction_vehicle']},
          {'num_class': 2, 'class_names': ['bus', 'trailer']},
          {'num_class': 1, 'class_names': ['barrier']},
          {'num_class': 2, 'class_names': ['motorcycle', 'bicycle']},
          {'num_class': 2, 'class_names': ['pedestrian', 'traffic_cone']}]
  common_heads: {'reg': [2, 2],
            'height': [1, 2],
            'dim': [3, 2],
            'rot': [2, 2],
            'vel': [2, 2]}
  bbox_coder: {'type': 'CenterPointBBoxCoder',
            'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            'max_num': 500,
            'score_threshold': 0.1,
            'out_size_factor': 2,
            'voxel_size': [0.5, 0.5, 8],
            'pc_range': [-50.0, -50.0, -5.0, 50.0, 50.0, 3.0],
            'code_size': 9}
  train_cfg: {'point_cloud_range': [-50.0, -50.0, -5.0, 50.0, 50.0, 3.0],
            'grid_size': [400, 400, 1],
            'voxel_size': [0.5, 0.5, 8],
            'out_size_factor': 2,
            'dense_reg': 1,
            'gaussian_overlap': 0.1,
            'max_objs': 500,
            'min_radius': 2,
            'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]} #! ori = 0.5, 0.5
  test_cfg: {'post_center_limit_range': [-61.2,-61.2, -10.0, 61.2, 61.2, 10.0],
            'max_per_img': 500,
            'max_pool_nms': False,
            'min_radius': [4, 12, 10, 1, 0.85, 0.175],
            'score_threshold': 0.1,
            'out_size_factor': 2,
            'voxel_size': [0.5, 0.5, 8],
            'nms_type': 'circle',
            'pre_max_size': 1000,
            'post_max_size': 83,
            'nms_thr': 0.2}
  in_channels: 256
  loss_cls: {'type': 'GaussianFocalLoss', 'reduction': 'mean'}

  loss_bbox: {'type': 'L1Loss', 'reduction': 'mean', 'loss_weight': 0.25}
  gaussian_overlap: 0.1
  min_radius: 2
  separate_head : {'type': 'SeparateHead', 'init_bias': -2.19, 'final_kernel': 3}