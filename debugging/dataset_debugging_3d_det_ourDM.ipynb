{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hydra\n",
    "from typing import Optional\n",
    "from collections.abc import Callable\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from data_module.lightning_data_module import DataModule\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. bevdepth data load O\n",
    "2. our data load O\n",
    "3. get item 비교 O\n",
    "4. dataloader -> 다른순서사진나옴\n",
    "4. 추후에 our dataset과 bevdepth dataset의 세세한 matrix 등도 전부 비교 필요 !! \n",
    "----------------\n",
    "0. bev depth 로직 파악 O\n",
    "1. BEVdepth's data 이용   \n",
    "    -  dataset은 datamodule이용(config일단 여따 일단 넣고)) O\n",
    "    - 기존 bevdepth와 동일한 데이터 가져오는지 확인 test  O\n",
    "    - dataloader config들은 hydra이용. O\n",
    "    - hydra 넣고 동일확인 test O\n",
    "2. model cvt로 이전 작업   \n",
    "## Dataset 값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "\n",
    "    cfg.loader.batch_size = 1\n",
    "\n",
    "    if 'split' not in cfg:\n",
    "        cfg.split = 'val'\n",
    "\n",
    "    if 'shuffle' not in cfg:\n",
    "        cfg.shuffle = False\n",
    "        \n",
    "def setup_config(cfg: DictConfig, override: Optional[Callable] = None):\n",
    "\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    OmegaConf.resolve(cfg)\n",
    "    OmegaConf.set_struct(cfg, True)\n",
    "\n",
    "\n",
    "def merge_rgbs(imgs):\n",
    "\n",
    "    fl = np.transpose(imgs[0], (1,2,0))\n",
    "    ff = np.transpose(imgs[1], (1,2,0))\n",
    "    fr = np.transpose(imgs[2], (1,2,0))\n",
    "\n",
    "    front = np.hstack([fl, ff, fr])\n",
    "\n",
    "    bl = np.transpose(imgs[5], (1,2,0))\n",
    "    bf = np.transpose(imgs[4], (1,2,0))\n",
    "    br = np.transpose(imgs[3], (1,2,0))\n",
    "\n",
    "    back = np.hstack([bl, bf, br])\n",
    "\n",
    "    whole = np.vstack([front, back])\n",
    "\n",
    "    return whole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_conf': {'img_mean': [123.675, 116.28, 103.53], 'img_std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'ida_aug_conf': {'resize_lim': [0.386, 0.55], 'final_dim': [256, 704], 'rot_lim': [-5.4, 5.4], 'H': 900, 'W': 1600, 'rand_flip': True, 'bot_pct_lim': [0.0, 0.0], 'cams': ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT'], 'Ncams': 6}, 'bda_aug_conf': {'rot_lim': [-22.5, 22.5], 'scale_lim': [0.95, 1.05], 'flip_dx_ratio': 0.5, 'flip_dy_ratio': 0.5}, 'data_root': '/usr/src/nuscenes', 'num_sweeps': 0, 'sweep_idxes': [], 'key_idxes': [], 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'use_fusion': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#! Our dataloader\n",
    "# # *  config setup  * #\n",
    "CONFIG_PATH = '/usr/src/CV_For_Autonomous_Driving/config'\n",
    "\n",
    "with initialize_config_dir(config_dir=CONFIG_PATH):\n",
    "    cfg = compose(config_name='default_config_debug.yaml')\n",
    "\n",
    "print(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "#! Our dataloader\n",
    "# # *  config setup  * #\n",
    "CONFIG_PATH = '/usr/src/CV_For_Autonomous_Driving/config'\n",
    "\n",
    "with initialize_config_dir(config_dir=CONFIG_PATH):\n",
    "    cfg = compose(config_name='default_config_debug.yaml')\n",
    "\n",
    "    \n",
    "setup_config(cfg, setup)\n",
    "\n",
    "# dataset list 만드는 test\n",
    "DM = DataModule('nusc_det_dataset', cfg.data, cfg.loader)\n",
    "# split = 'train'\n",
    "# data_cfg_our = DM.data_cfg\n",
    "# datasets = DM.get_data(split=split,\n",
    "#                             **data_cfg_our)\n",
    "train_dataloader = DM.train_dataloader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 15:10:34,139 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-15 15:10:34,151 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([128, 256, 4, 4]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,152 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,153 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,154 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([128, 512, 2, 2]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,155 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,156 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,157 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([1024, 128, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,158 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,159 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,160 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([2048, 128, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,161 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,162 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,188 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2023-01-15 15:10:34,189 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2023-01-15 15:10:34,190 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2023-01-15 15:10:34,324 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2023-01-15 15:10:34,513 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "2023-01-15 15:10:34,651 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,654 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,657 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,660 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,665 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,671 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:34,682 - mmcv - INFO - \n",
      "conv1.weight - torch.Size([160, 80, 7, 7]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,683 - mmcv - INFO - \n",
      "bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,684 - mmcv - INFO - \n",
      "bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,685 - mmcv - INFO - \n",
      "layer1.0.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,686 - mmcv - INFO - \n",
      "layer1.0.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,687 - mmcv - INFO - \n",
      "layer1.0.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,688 - mmcv - INFO - \n",
      "layer1.0.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,689 - mmcv - INFO - \n",
      "layer1.0.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,690 - mmcv - INFO - \n",
      "layer1.0.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,691 - mmcv - INFO - \n",
      "layer1.1.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,692 - mmcv - INFO - \n",
      "layer1.1.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,693 - mmcv - INFO - \n",
      "layer1.1.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,694 - mmcv - INFO - \n",
      "layer1.1.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,695 - mmcv - INFO - \n",
      "layer1.1.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,696 - mmcv - INFO - \n",
      "layer1.1.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,697 - mmcv - INFO - \n",
      "layer2.0.conv1.weight - torch.Size([320, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,698 - mmcv - INFO - \n",
      "layer2.0.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,699 - mmcv - INFO - \n",
      "layer2.0.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,699 - mmcv - INFO - \n",
      "layer2.0.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,700 - mmcv - INFO - \n",
      "layer2.0.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,701 - mmcv - INFO - \n",
      "layer2.0.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,702 - mmcv - INFO - \n",
      "layer2.0.downsample.0.weight - torch.Size([320, 160, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,703 - mmcv - INFO - \n",
      "layer2.0.downsample.1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,707 - mmcv - INFO - \n",
      "layer2.0.downsample.1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,708 - mmcv - INFO - \n",
      "layer2.1.conv1.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,709 - mmcv - INFO - \n",
      "layer2.1.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,710 - mmcv - INFO - \n",
      "layer2.1.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,711 - mmcv - INFO - \n",
      "layer2.1.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,712 - mmcv - INFO - \n",
      "layer2.1.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,713 - mmcv - INFO - \n",
      "layer2.1.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,714 - mmcv - INFO - \n",
      "layer3.0.conv1.weight - torch.Size([640, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,714 - mmcv - INFO - \n",
      "layer3.0.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,715 - mmcv - INFO - \n",
      "layer3.0.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,716 - mmcv - INFO - \n",
      "layer3.0.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,717 - mmcv - INFO - \n",
      "layer3.0.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,718 - mmcv - INFO - \n",
      "layer3.0.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,719 - mmcv - INFO - \n",
      "layer3.0.downsample.0.weight - torch.Size([640, 320, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,720 - mmcv - INFO - \n",
      "layer3.0.downsample.1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,721 - mmcv - INFO - \n",
      "layer3.0.downsample.1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,721 - mmcv - INFO - \n",
      "layer3.1.conv1.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,722 - mmcv - INFO - \n",
      "layer3.1.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,723 - mmcv - INFO - \n",
      "layer3.1.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,724 - mmcv - INFO - \n",
      "layer3.1.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,724 - mmcv - INFO - \n",
      "layer3.1.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,725 - mmcv - INFO - \n",
      "layer3.1.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:34,761 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-15 15:10:34,785 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([80, 64, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,786 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,787 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,788 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([160, 64, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,789 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,790 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,791 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([320, 64, 4, 4]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,792 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,793 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,794 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([640, 64, 8, 8]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:34,795 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:34,796 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,331 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-15 15:10:35,342 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([128, 256, 4, 4]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,343 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,344 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,345 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([128, 512, 2, 2]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,346 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,347 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,348 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([1024, 128, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,349 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,350 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,351 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([2048, 128, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,352 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,353 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,371 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2023-01-15 15:10:35,373 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2023-01-15 15:10:35,374 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2023-01-15 15:10:35,505 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2023-01-15 15:10:35,687 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "2023-01-15 15:10:35,816 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,819 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,822 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,825 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,830 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,836 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-15 15:10:35,848 - mmcv - INFO - \n",
      "conv1.weight - torch.Size([160, 80, 7, 7]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,849 - mmcv - INFO - \n",
      "bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,850 - mmcv - INFO - \n",
      "bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,851 - mmcv - INFO - \n",
      "layer1.0.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,852 - mmcv - INFO - \n",
      "layer1.0.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,853 - mmcv - INFO - \n",
      "layer1.0.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,854 - mmcv - INFO - \n",
      "layer1.0.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,855 - mmcv - INFO - \n",
      "layer1.0.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,856 - mmcv - INFO - \n",
      "layer1.0.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,857 - mmcv - INFO - \n",
      "layer1.1.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,858 - mmcv - INFO - \n",
      "layer1.1.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,859 - mmcv - INFO - \n",
      "layer1.1.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,860 - mmcv - INFO - \n",
      "layer1.1.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,860 - mmcv - INFO - \n",
      "layer1.1.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,861 - mmcv - INFO - \n",
      "layer1.1.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,862 - mmcv - INFO - \n",
      "layer2.0.conv1.weight - torch.Size([320, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,863 - mmcv - INFO - \n",
      "layer2.0.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,864 - mmcv - INFO - \n",
      "layer2.0.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,864 - mmcv - INFO - \n",
      "layer2.0.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,865 - mmcv - INFO - \n",
      "layer2.0.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,866 - mmcv - INFO - \n",
      "layer2.0.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,867 - mmcv - INFO - \n",
      "layer2.0.downsample.0.weight - torch.Size([320, 160, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,868 - mmcv - INFO - \n",
      "layer2.0.downsample.1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,868 - mmcv - INFO - \n",
      "layer2.0.downsample.1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,869 - mmcv - INFO - \n",
      "layer2.1.conv1.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,870 - mmcv - INFO - \n",
      "layer2.1.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,871 - mmcv - INFO - \n",
      "layer2.1.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,876 - mmcv - INFO - \n",
      "layer2.1.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,876 - mmcv - INFO - \n",
      "layer2.1.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,877 - mmcv - INFO - \n",
      "layer2.1.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,878 - mmcv - INFO - \n",
      "layer3.0.conv1.weight - torch.Size([640, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,879 - mmcv - INFO - \n",
      "layer3.0.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,880 - mmcv - INFO - \n",
      "layer3.0.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,881 - mmcv - INFO - \n",
      "layer3.0.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,881 - mmcv - INFO - \n",
      "layer3.0.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,882 - mmcv - INFO - \n",
      "layer3.0.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,883 - mmcv - INFO - \n",
      "layer3.0.downsample.0.weight - torch.Size([640, 320, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,884 - mmcv - INFO - \n",
      "layer3.0.downsample.1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,885 - mmcv - INFO - \n",
      "layer3.0.downsample.1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,886 - mmcv - INFO - \n",
      "layer3.1.conv1.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,886 - mmcv - INFO - \n",
      "layer3.1.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,887 - mmcv - INFO - \n",
      "layer3.1.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,887 - mmcv - INFO - \n",
      "layer3.1.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,888 - mmcv - INFO - \n",
      "layer3.1.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,889 - mmcv - INFO - \n",
      "layer3.1.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-15 15:10:35,925 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-15 15:10:35,949 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([80, 64, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,951 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,952 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,953 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([160, 64, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,954 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,955 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,956 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([320, 64, 4, 4]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,957 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,958 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,959 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([640, 64, 8, 8]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-15 15:10:35,960 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-15 15:10:35,961 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "#! BEVDepth dataloader\n",
    "from model_module.bev_depth_lss_r50_256x704_128x128_24e_2key import BEVDepthLightningModel\n",
    "model_module = BEVDepthLightningModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "train = iter(train_dataloader)\n",
    "train_bd= iter(model_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = next(train)\n",
    "data_bd = next(train_bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 Data인지 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.imgs :  [tensor(True), tensor(True), tensor(True), tensor(True)]\n",
      "0.imgs :  tensor(True)\n",
      "1.mats_dict :  [True, True, True, True, True]\n",
      "2.timestamps :  tensor(True)\n",
      "3.img_metas : \n",
      "True\n",
      "[ True  True  True]\n",
      "[ True  True  True  True]\n",
      "True\n",
      "True\n",
      "[ True  True  True]\n",
      "[ True  True  True  True]\n",
      "True\n",
      "True\n",
      "[ True  True  True]\n",
      "[ True  True  True  True]\n",
      "True\n",
      "True\n",
      "[ True  True  True]\n",
      "[ True  True  True  True]\n",
      "True\n",
      "4.gt_boxes :  [tensor(True), tensor(True), tensor(True), tensor(True)]\n",
      "5.gt_labaels :  [tensor(True), tensor(True), tensor(True), tensor(True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print('0.imgs : ', [torch.all(data[0][i]) == torch.all(data_bd[0][i]) for i in range(len(data[0])) ])\n",
    "print('0.imgs : ',torch.all(data[0]) == torch.all(data_bd[0]))\n",
    "print('1.mats_dict : ',[np.all(np.asarray(data[1][i])) == np.all(np.asarray(data_bd[1][i])) \\\n",
    "                for i in data[1].keys()])\n",
    "print('2.timestamps : ',torch.all(data[2]) == torch.all(data_bd[2]))\n",
    "data3 =[np.asarray(data[3][i][k])== np.asarray(data_bd[3][i][k]) for i in range(len(data[3])) for k in data[3][i].keys() ]\n",
    "print('3.img_metas : ',*data3, sep='\\n')\n",
    "print('4.gt_boxes : ', [torch.all(data[4][i]) == torch.all(data_bd[4][i]) for i in range(len(data[4])) ])\n",
    "print('5.gt_labaels : ', [torch.all(data[5][i]) == torch.all(data_bd[5][i]) for i in range(len(data[5])) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_bd[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'num_workers': 8, 'pin_memory': True, 'prefetch_factor': 8}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'past_bd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1114672/776773667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0.imgs : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_bd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_bd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0.imgs : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print('1.mats_dict : ',[np.all(np.asarray(data[1][i])) == np.all(np.asarray(data_bd[1][i])) \\\n",
      "\u001b[0;31mNameError\u001b[0m: name 'past_bd' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print('0.imgs : ', [torch.all(past_bd[0][i]) == torch.all(data_bd[0][i]) for i in range(len(past_bd[0])) ])\n",
    "print('0.imgs : ',torch.all(data[0]) == torch.all(past[0]))\n",
    "print('1.mats_dict : ',[np.all(np.asarray(data[1][i])) == np.all(np.asarray(data_bd[1][i])) \\\n",
    "                for i in data[1].keys()])\n",
    "print('2.timestamps : ',torch.all(data[2]) == torch.all(past[2]))\n",
    "data3 =[np.asarray(data_bd[3][i][k])== np.asarray(past[3][i][k]) for i in range(len(data[3])) for k in data[3][i].keys() ]\n",
    "print('3.img_metas : ',*data3, sep='\\n')\n",
    "print('4.gt_boxes : ', [torch.all(data[4][i]) == torch.all(data_bd[4][i]) for i in range(len(data[4])) ])\n",
    "print('5.gt_labaels : ', [torch.all(data[5][i]) == torch.all(data_bd[5][i]) for i in range(len(data[5])) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_bd = data_bd\n",
    "past = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28130"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 900\n",
    "W = 1600\n",
    "final_dim = (256, 704)\n",
    "backbone_conf = {\n",
    "    'x_bound': [-51.2, 51.2, 0.8],\n",
    "    'y_bound': [-51.2, 51.2, 0.8],\n",
    "    'z_bound': [-5, 3, 8],\n",
    "    'd_bound': [2.0, 58.0, 0.5],\n",
    "    'final_dim':\n",
    "    final_dim,\n",
    "    'output_channels':\n",
    "    80,\n",
    "    'downsample_factor':\n",
    "    16,\n",
    "    'img_backbone_conf':\n",
    "    dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        frozen_stages=0,\n",
    "        out_indices=[0, 1, 2, 3],\n",
    "        norm_eval=False,\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),\n",
    "    ),\n",
    "    'img_neck_conf':\n",
    "    dict(\n",
    "        type='SECONDFPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        upsample_strides=[0.25, 0.5, 1, 2],\n",
    "        out_channels=[128, 128, 128, 128],\n",
    "    ),\n",
    "    'depth_net_conf':\n",
    "    dict(in_channels=512, mid_channels=512)\n",
    "}\n",
    "\n",
    "\n",
    "bev_backbone = dict(\n",
    "    type='ResNet',\n",
    "    in_channels=80,\n",
    "    depth=18,\n",
    "    num_stages=3,\n",
    "    strides=(1, 2, 2),\n",
    "    dilations=(1, 1, 1),\n",
    "    out_indices=[0, 1, 2],\n",
    "    norm_eval=False,\n",
    "    base_channels=160,\n",
    ")\n",
    "\n",
    "bev_neck = dict(type='SECONDFPN',\n",
    "                in_channels=[80, 160, 320, 640],\n",
    "                upsample_strides=[1, 2, 4, 8],\n",
    "                out_channels=[64, 64, 64, 64])\n",
    "\n",
    "CLASSES = [\n",
    "    'car',\n",
    "    'truck',\n",
    "    'construction_vehicle',\n",
    "    'bus',\n",
    "    'trailer',\n",
    "    'barrier',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'pedestrian',\n",
    "    'traffic_cone',\n",
    "]\n",
    "\n",
    "TASKS = [\n",
    "    dict(num_class=1, class_names=['car']),\n",
    "    dict(num_class=2, class_names=['truck', 'construction_vehicle']),\n",
    "    dict(num_class=2, class_names=['bus', 'trailer']),\n",
    "    dict(num_class=1, class_names=['barrier']),\n",
    "    dict(num_class=2, class_names=['motorcycle', 'bicycle']),\n",
    "    dict(num_class=2, class_names=['pedestrian', 'traffic_cone']),\n",
    "]\n",
    "\n",
    "common_heads = dict(reg=(2, 2),\n",
    "                    height=(1, 2),\n",
    "                    dim=(3, 2),\n",
    "                    rot=(2, 2),\n",
    "                    vel=(2, 2))\n",
    "\n",
    "bbox_coder = dict(\n",
    "    type='CenterPointBBoxCoder',\n",
    "    post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
    "    max_num=500,\n",
    "    score_threshold=0.1,\n",
    "    out_size_factor=4,\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    pc_range=[-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
    "    code_size=9,\n",
    ")\n",
    "\n",
    "train_cfg = dict(\n",
    "    point_cloud_range=[-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
    "    grid_size=[512, 512, 1],\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    out_size_factor=4,\n",
    "    dense_reg=1,\n",
    "    gaussian_overlap=0.1,\n",
    "    max_objs=500,\n",
    "    min_radius=2,\n",
    "    code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "test_cfg = dict(\n",
    "    post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
    "    max_per_img=500,\n",
    "    max_pool_nms=False,\n",
    "    min_radius=[4, 12, 10, 1, 0.85, 0.175],\n",
    "    score_threshold=0.1,\n",
    "    out_size_factor=4,\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    nms_type='circle',\n",
    "    pre_max_size=1000,\n",
    "    post_max_size=83,\n",
    "    nms_thr=0.2,\n",
    ")\n",
    "\n",
    "head_conf = {\n",
    "    'bev_backbone_conf': bev_backbone,\n",
    "    'bev_neck_conf': bev_neck,\n",
    "    'tasks': TASKS,\n",
    "    'common_heads': common_heads,\n",
    "    'bbox_coder': bbox_coder,\n",
    "    'train_cfg': train_cfg,\n",
    "    'test_cfg': test_cfg,\n",
    "    'in_channels': 256,  # Equal to bev_neck output_channels.\n",
    "    'loss_cls': dict(type='GaussianFocalLoss', reduction='mean'),\n",
    "    'loss_bbox': dict(type='L1Loss', reduction='mean', loss_weight=0.25),\n",
    "    'gaussian_overlap': 0.1,\n",
    "    'min_radius': 2,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "backbone_conf = {\n",
    "    'x_bound': [-51.2, 51.2, 0.8],\n",
    "    'y_bound': [-51.2, 51.2, 0.8],\n",
    "    'z_bound': [-5, 3, 8],\n",
    "    'd_bound': [2.0, 58.0, 0.5],\n",
    "    'final_dim':\n",
    "    final_dim,\n",
    "    'output_channels':\n",
    "    80,\n",
    "    'downsample_factor':\n",
    "    16,\n",
    "    'img_backbone_conf':\n",
    "    dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        frozen_stages=0,\n",
    "        out_indices=[0, 1, 2, 3],\n",
    "        norm_eval=False,\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),\n",
    "    ),\n",
    "    'img_neck_conf':\n",
    "    dict(\n",
    "        type='SECONDFPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        upsample_strides=[0.25, 0.5, 1, 2],\n",
    "        out_channels=[128, 128, 128, 128],\n",
    "    ),\n",
    "    'depth_net_conf':\n",
    "    dict(in_channels=512, mid_channels=512)\n",
    "}\n",
    "\n",
    "\n",
    "bev_backbone = dict(\n",
    "    type='ResNet',\n",
    "    in_channels=80,\n",
    "    depth=18,\n",
    "    num_stages=3,\n",
    "    strides=(1, 2, 2),\n",
    "    dilations=(1, 1, 1),\n",
    "    out_indices=[0, 1, 2],\n",
    "    norm_eval=False,\n",
    "    base_channels=160,\n",
    ")\n",
    "\n",
    "bev_neck = dict(type='SECONDFPN',\n",
    "                in_channels=[80, 160, 320, 640],\n",
    "                upsample_strides=[1, 2, 4, 8],\n",
    "                out_channels=[64, 64, 64, 64])\n",
    "\n",
    "CLASSES = [\n",
    "    'car',\n",
    "    'truck',\n",
    "    'construction_vehicle',\n",
    "    'bus',\n",
    "    'trailer',\n",
    "    'barrier',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'pedestrian',\n",
    "    'traffic_cone',\n",
    "]\n",
    "\n",
    "TASKS = [\n",
    "    dict(num_class=1, class_names=['car']),\n",
    "    dict(num_class=2, class_names=['truck', 'construction_vehicle']),\n",
    "    dict(num_class=2, class_names=['bus', 'trailer']),\n",
    "    dict(num_class=1, class_names=['barrier']),\n",
    "    dict(num_class=2, class_names=['motorcycle', 'bicycle']),\n",
    "    dict(num_class=2, class_names=['pedestrian', 'traffic_cone']),\n",
    "]\n",
    "\n",
    "common_heads = dict(reg=(2, 2),\n",
    "                    height=(1, 2),\n",
    "                    dim=(3, 2),\n",
    "                    rot=(2, 2),\n",
    "                    vel=(2, 2))\n",
    "\n",
    "bbox_coder = dict(\n",
    "    type='CenterPointBBoxCoder',\n",
    "    post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
    "    max_num=500,\n",
    "    score_threshold=0.1,\n",
    "    out_size_factor=4,\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    pc_range=[-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
    "    code_size=9,\n",
    ")\n",
    "\n",
    "train_cfg = dict(\n",
    "    point_cloud_range=[-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
    "    grid_size=[512, 512, 1],\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    out_size_factor=4,\n",
    "    dense_reg=1,\n",
    "    gaussian_overlap=0.1,\n",
    "    max_objs=500,\n",
    "    min_radius=2,\n",
    "    code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "test_cfg = dict(\n",
    "    post_center_limit_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
    "    max_per_img=500,\n",
    "    max_pool_nms=False,\n",
    "    min_radius=[4, 12, 10, 1, 0.85, 0.175],\n",
    "    score_threshold=0.1,\n",
    "    out_size_factor=4,\n",
    "    voxel_size=[0.2, 0.2, 8],\n",
    "    nms_type='circle',\n",
    "    pre_max_size=1000,\n",
    "    post_max_size=83,\n",
    "    nms_thr=0.2,\n",
    ")\n",
    "\n",
    "head_conf = {\n",
    "    'bev_backbone_conf': bev_backbone,\n",
    "    'bev_neck_conf': bev_neck,\n",
    "    'tasks': TASKS,\n",
    "    'common_heads': common_heads,\n",
    "    'bbox_coder': bbox_coder,\n",
    "    'train_cfg': train_cfg,\n",
    "    'test_cfg': test_cfg,\n",
    "    'in_channels': 256,  # Equal to bev_neck output_channels.\n",
    "    'loss_cls': dict(type='GaussianFocalLoss', reduction='mean'),\n",
    "    'loss_bbox': dict(type='L1Loss', reduction='mean', loss_weight=0.25),\n",
    "    'gaussian_overlap': 0.1,\n",
    "    'min_radius': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_bound': [-51.2, 51.2, 0.8],\n",
       " 'y_bound': [-51.2, 51.2, 0.8],\n",
       " 'z_bound': [-5, 3, 8],\n",
       " 'd_bound': [2.0, 58.0, 0.5],\n",
       " 'final_dim': (256, 704),\n",
       " 'output_channels': 80,\n",
       " 'downsample_factor': 16,\n",
       " 'img_backbone_conf': {'type': 'ResNet',\n",
       "  'depth': 50,\n",
       "  'frozen_stages': 0,\n",
       "  'out_indices': [0, 1, 2, 3],\n",
       "  'norm_eval': False,\n",
       "  'init_cfg': {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}},\n",
       " 'img_neck_conf': {'type': 'SECONDFPN',\n",
       "  'in_channels': [256, 512, 1024, 2048],\n",
       "  'upsample_strides': [0.25, 0.5, 1, 2],\n",
       "  'out_channels': [128, 128, 128, 128]},\n",
       " 'depth_net_conf': {'in_channels': 512, 'mid_channels': 512}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ResNet',\n",
       " 'in_channels': 80,\n",
       " 'depth': 18,\n",
       " 'num_stages': 3,\n",
       " 'strides': (1, 2, 2),\n",
       " 'dilations': (1, 1, 1),\n",
       " 'out_indices': [0, 1, 2],\n",
       " 'norm_eval': False,\n",
       " 'base_channels': 160}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bev_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'SECONDFPN',\n",
       " 'in_channels': [80, 160, 320, 640],\n",
       " 'upsample_strides': [1, 2, 4, 8],\n",
       " 'out_channels': [64, 64, 64, 64]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bev_neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_class': 1, 'class_names': ['car']},\n",
       " {'num_class': 2, 'class_names': ['truck', 'construction_vehicle']},\n",
       " {'num_class': 2, 'class_names': ['bus', 'trailer']},\n",
       " {'num_class': 1, 'class_names': ['barrier']},\n",
       " {'num_class': 2, 'class_names': ['motorcycle', 'bicycle']},\n",
       " {'num_class': 2, 'class_names': ['pedestrian', 'traffic_cone']}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg': (2, 2), 'height': (1, 2), 'dim': (3, 2), 'rot': (2, 2), 'vel': (2, 2)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CenterPointBBoxCoder',\n",
       " 'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
       " 'max_num': 500,\n",
       " 'score_threshold': 0.1,\n",
       " 'out_size_factor': 4,\n",
       " 'voxel_size': [0.2, 0.2, 8],\n",
       " 'pc_range': [-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
       " 'code_size': 9}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'point_cloud_range': [-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
       " 'grid_size': [512, 512, 1],\n",
       " 'voxel_size': [0.2, 0.2, 8],\n",
       " 'out_size_factor': 4,\n",
       " 'dense_reg': 1,\n",
       " 'gaussian_overlap': 0.1,\n",
       " 'max_objs': 500,\n",
       " 'min_radius': 2,\n",
       " 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_center_limit_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
       " 'max_per_img': 500,\n",
       " 'max_pool_nms': False,\n",
       " 'min_radius': [4, 12, 10, 1, 0.85, 0.175],\n",
       " 'score_threshold': 0.1,\n",
       " 'out_size_factor': 4,\n",
       " 'voxel_size': [0.2, 0.2, 8],\n",
       " 'nms_type': 'circle',\n",
       " 'pre_max_size': 1000,\n",
       " 'post_max_size': 83,\n",
       " 'nms_thr': 0.2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bev_backbone_conf': {'type': 'ResNet',\n",
       "  'in_channels': 80,\n",
       "  'depth': 18,\n",
       "  'num_stages': 3,\n",
       "  'strides': (1, 2, 2),\n",
       "  'dilations': (1, 1, 1),\n",
       "  'out_indices': [0, 1, 2],\n",
       "  'norm_eval': False,\n",
       "  'base_channels': 160},\n",
       " 'bev_neck_conf': {'type': 'SECONDFPN',\n",
       "  'in_channels': [80, 160, 320, 640],\n",
       "  'upsample_strides': [1, 2, 4, 8],\n",
       "  'out_channels': [64, 64, 64, 64]},\n",
       " 'tasks': [{'num_class': 1, 'class_names': ['car']},\n",
       "  {'num_class': 2, 'class_names': ['truck', 'construction_vehicle']},\n",
       "  {'num_class': 2, 'class_names': ['bus', 'trailer']},\n",
       "  {'num_class': 1, 'class_names': ['barrier']},\n",
       "  {'num_class': 2, 'class_names': ['motorcycle', 'bicycle']},\n",
       "  {'num_class': 2, 'class_names': ['pedestrian', 'traffic_cone']}],\n",
       " 'common_heads': {'reg': (2, 2),\n",
       "  'height': (1, 2),\n",
       "  'dim': (3, 2),\n",
       "  'rot': (2, 2),\n",
       "  'vel': (2, 2)},\n",
       " 'bbox_coder': {'type': 'CenterPointBBoxCoder',\n",
       "  'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n",
       "  'max_num': 500,\n",
       "  'score_threshold': 0.1,\n",
       "  'out_size_factor': 4,\n",
       "  'voxel_size': [0.2, 0.2, 8],\n",
       "  'pc_range': [-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
       "  'code_size': 9},\n",
       " 'train_cfg': {'point_cloud_range': [-51.2, -51.2, -5, 51.2, 51.2, 3],\n",
       "  'grid_size': [512, 512, 1],\n",
       "  'voxel_size': [0.2, 0.2, 8],\n",
       "  'out_size_factor': 4,\n",
       "  'dense_reg': 1,\n",
       "  'gaussian_overlap': 0.1,\n",
       "  'max_objs': 500,\n",
       "  'min_radius': 2,\n",
       "  'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5]},\n",
       " 'test_cfg': {'post_center_limit_range': [-61.2,\n",
       "   -61.2,\n",
       "   -10.0,\n",
       "   61.2,\n",
       "   61.2,\n",
       "   10.0],\n",
       "  'max_per_img': 500,\n",
       "  'max_pool_nms': False,\n",
       "  'min_radius': [4, 12, 10, 1, 0.85, 0.175],\n",
       "  'score_threshold': 0.1,\n",
       "  'out_size_factor': 4,\n",
       "  'voxel_size': [0.2, 0.2, 8],\n",
       "  'nms_type': 'circle',\n",
       "  'pre_max_size': 1000,\n",
       "  'post_max_size': 83,\n",
       "  'nms_thr': 0.2},\n",
       " 'in_channels': 256,\n",
       " 'loss_cls': {'type': 'GaussianFocalLoss', 'reduction': 'mean'},\n",
       " 'loss_bbox': {'type': 'L1Loss', 'reduction': 'mean', 'loss_weight': 0.25},\n",
       " 'gaussian_overlap': 0.1,\n",
       " 'min_radius': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'SeparateHead', 'init_bias': -2.19, 'final_kernel': 3}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(type='SeparateHead',\n",
    "                           init_bias=-2.19,\n",
    "                           final_kernel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "121f8c44e5968bbcd51100cc03ceec35b3b1222dae64e7f895d4cb48ef859830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
