{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hydra\n",
    "from typing import Optional\n",
    "from collections.abc import Callable\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from data_module.visualize.vis_lightning_data_module import DataModule\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup(cfg):\n",
    "\n",
    "    cfg.loader.batch_size = 1\n",
    "\n",
    "    if 'split' not in cfg:\n",
    "        cfg.split = 'val'\n",
    "\n",
    "    if 'shuffle' not in cfg:\n",
    "        cfg.shuffle = False\n",
    "        \n",
    "def setup_config(cfg: DictConfig, override: Optional[Callable] = None):\n",
    "\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    OmegaConf.resolve(cfg)\n",
    "    OmegaConf.set_struct(cfg, True)\n",
    "\n",
    "\n",
    "def merge_rgbs(imgs):\n",
    "\n",
    "    fl = np.transpose(imgs[0], (1,2,0))\n",
    "    ff = np.transpose(imgs[1], (1,2,0))\n",
    "    fr = np.transpose(imgs[2], (1,2,0))\n",
    "\n",
    "    front = np.hstack([fl, ff, fr])\n",
    "\n",
    "    bl = np.transpose(imgs[5], (1,2,0))\n",
    "    bf = np.transpose(imgs[4], (1,2,0))\n",
    "    br = np.transpose(imgs[3], (1,2,0))\n",
    "\n",
    "    back = np.hstack([bl, bf, br])\n",
    "\n",
    "    whole = np.vstack([front, back])\n",
    "\n",
    "    return whole\n",
    "\n",
    "def vis_gt(bev):\n",
    "    bev = np.transpose(bev, (1, 2, 0))\n",
    "    area = bev[:,:,0] + bev[:,:,1]\n",
    "    divider = bev[:,:,2] + bev[:,:,3]\n",
    "    vehicle = bev[:,:,4] + bev[:,:,5] + bev[:,:,6] + bev[:,:,7]\n",
    "\n",
    "    h, w = area.shape\n",
    "    vis = np.full((h, w, 3), 255, dtype='uint8')\n",
    "\n",
    "    \n",
    "    for i, bibev in enumerate([area, divider, vehicle]):\n",
    "    # for i, bibev in enumerate([area, vehicle]):\n",
    "        vis[bibev!=0,:] = mapping[i]\n",
    "    \n",
    "    vis[95:105, 98:102, :] = (255, 0, 0)\n",
    "\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# *  config setup  * #\n",
    "CONFIG_PATH = '/usr/src/CV_For_Autonomous_Driving/config'\n",
    "\n",
    "with initialize_config_dir(config_dir=CONFIG_PATH):\n",
    "    cfg = compose(config_name='default_config.yaml')\n",
    "    \n",
    "setup_config(cfg, setup)\n",
    "\n",
    "\n",
    "# dataset list 만드는 test\n",
    "DM = DataModule(cfg.data, cfg.loader)\n",
    "\n",
    "split = 'val'\n",
    "data_cfg = DM.data_cfg\n",
    "datasets = DM.get_data(split=split,\n",
    "                            **data_cfg)\n",
    "\n",
    "# datasets = DM.get_dataset_bevdepth(split=split,\n",
    "#                             **data_cfg)\n",
    "\n",
    "print(f'In {split} dataset, {len(datasets)} scenes are included.')\n",
    "\n",
    "\n",
    "# dataset init test\n",
    "# total = 0\n",
    "# for dataset in datasets:\n",
    "#     total += len(dataset)\n",
    "\n",
    "# print(f'nuscenes train has {total} data samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset __getitem__ test\n",
    "data = datasets[0].__getitem__(0) #! Dataset output LIST 임\n",
    "# for k, v in data.items():\n",
    "#     print(f'{k}: {v.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: depth ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 16))\n",
    "\n",
    "# fig.canvas.set_window_title(sample_token)\n",
    "img = np.transpose(data['image'][0].numpy(), (1,2,0))\n",
    "depth = data['depth'][0].numpy()\n",
    "# debug_d = data['debug_d'][0]\n",
    "\n",
    "h, w = depth.shape\n",
    "\n",
    "x = np.linspace(0, w, w)\n",
    "y = np.linspace(0, h, h)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "\n",
    "xs_flat = xs.flatten()\n",
    "ys_flat = ys.flatten()\n",
    "depth_flat = depth.flatten()\n",
    "\n",
    "mask = depth_flat > 1e-5\n",
    "xs_filter = xs_flat[mask]\n",
    "ys_filter = ys_flat[mask]\n",
    "depth_filter = depth_flat[mask]\n",
    "\n",
    "print(np.unique(depth_filter))\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.scatter(xs_filter, ys_filter, c=depth_filter, s=3, cmap='coolwarm') \n",
    "\n",
    "\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(depth_filter)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: 3d bbox ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d bbox \n",
    "mapping = {0: (255, 153, 51),\n",
    "            1: (0, 128, 255),\n",
    "            2: (0, 0, 255)}\n",
    "\n",
    "bev_map = np.full((200, 200, 3), 255)\n",
    "\n",
    "gt_bbox = data['gt_box']\n",
    "gt_cls = data['gt_label'].numpy()\n",
    "\n",
    "# merge images\n",
    "merged_imgs = merge_rgbs(data['image'].numpy())\n",
    "# bev: torch.Size([200, 200, 12])\n",
    "bev = vis_gt(data['bev'].numpy())\n",
    "\n",
    "np.unique(data['bev'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['gt_box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_mapping = {}\n",
    "for i in range(10):\n",
    "    cls_mapping[i] = np.random.rand((3))*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_module.dataset.utils import *\n",
    "#(0,0), top left\n",
    "bev_cfg = {'h': 200, 'w': 200, \n",
    "                    'h_meters': 100.0, 'w_meters': 100.0, 'offset': 0.0}\n",
    "meter2pix = get_bev_meter2pix_matrix(bev_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "bev_map = np.full((200, 200, 3), 255)\n",
    "for i in range(len(gt_bbox)):\n",
    "    l, w, h = gt_bbox[i][3:6] \n",
    "\n",
    "    # 3D bounding box corners. (Convention: x points forward, y to the left, z up.)\n",
    "    x_corners = l / 2 * np.array([1,  1,  1,  1, -1, -1, -1, -1])\n",
    "    y_corners = w / 2 * np.array([1, -1, -1,  1,  1, -1, -1,  1])\n",
    "    z_corners = h / 2 * np.array([1,  1, -1, -1,  1,  1, -1, -1])\n",
    "    corners = np.vstack((x_corners, y_corners, z_corners))\n",
    "\n",
    "    # Rotate\n",
    "    #! 필수!! \n",
    "    # print(gt_bbox[i][6])\n",
    "    corners = np.dot(gt_bbox[i][6].rotation_matrix, corners)\n",
    "\n",
    "    # Translate\n",
    "    x, y, z = gt_bbox[i][:3]\n",
    "    corners[0, :] = corners[0, :] + x\n",
    "    corners[1, :] = corners[1, :] + y\n",
    "    corners[2, :] = corners[2, :] + z\n",
    "    # print('corners', corners.shape)\n",
    "    p =corners[:, [2, 3, 7, 6]]\n",
    "\n",
    "\n",
    "    \n",
    "    gt_box = gt_bbox[i]\n",
    "\n",
    "\n",
    "    h, w = 200,200\n",
    "    V = meter2pix \n",
    "    S = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "\n",
    "    p = np.pad(p, ((0, 1), (0, 0)), constant_values=1.0)     \n",
    "    p = V @ S @ p  \n",
    "    if (p[0][0] < 0 or p[0][0]> 200) or (p[0][3] < 0 or p[0][3] > 200) \\\n",
    "        or (p[1][0] < 0 or p[1][0]  > 200) or (p[1][3]  < 0 or p[1][3] > 200):\n",
    "        continue \n",
    "\n",
    "    bbox = p[:2, :4]\n",
    "    bev_map = cv2.fillPoly(bev_map.astype(np.int32), [bbox.round().astype(np.int32).T], 1, cv2.LINE_8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bev_map)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data['bev'].numpy())\n",
    "plt.imshow(bev)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(merged_imgs)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "121f8c44e5968bbcd51100cc03ceec35b3b1222dae64e7f895d4cb48ef859830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
