{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator(nn.Module):\n",
    "\n",
    "    def __init__(self, reduce_dim, chs):\n",
    "        super(Aggregator, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for channel in chs:\n",
    "            layer = nn.Conv2d(channel, reduce_dim, 1)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.aggregator = nn.Sequential(\n",
    "            nn.Conv2d(reduce_dim*(len(chs)), reduce_dim, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(reduce_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, target, feats):\n",
    "        _,_,H,W = target.size() # B,C,H,W\n",
    "        \n",
    "        sum_feats=[self.layers[0](target)]\n",
    "        for i, feat in enumerate(feats):\n",
    "            feat = self.layers[i+1](feat)\n",
    "            sum_feats.append(F.interpolate(feat, (H,W), mode='bilinear', align_corners=True))\n",
    "\n",
    "        context = self.aggregator(torch.cat(sum_feats, dim=1))\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, reduce_dim=64):\n",
    "        super(Down, self).__init__()\n",
    "\n",
    "        self.down = nn.Sequential(\n",
    "            nn.Conv2d(reduce_dim, reduce_dim, kernel_size=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(reduce_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(reduce_dim, reduce_dim, kernel_size=1, stride=1,bias=False),\n",
    "            nn.BatchNorm2d(reduce_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "class AggOnce(nn.Module):\n",
    "    def __init__(self, reduce_dim=64, chs=[32, 56, 160, 448, 448, 448]):\n",
    "        super(AggOnce, self).__init__()\n",
    "\n",
    "        self.agg = Aggregator(reduce_dim, chs)\n",
    "\n",
    "        self.down = nn.Sequential(Down(reduce_dim), \n",
    "                                Down(reduce_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        f4 = self.agg(x[0], x[1:])\n",
    "        f16 = self.down(f4)\n",
    "        return f4, f16\n",
    "\n",
    "class AggTwice(nn.Module):\n",
    "    def __init__(self, reduce_dim=64):\n",
    "        super(AggTwice, self).__init__()\n",
    "\n",
    "        self.agg16 = Aggregator(reduce_dim, [160, 448, 448, 448])\n",
    "        self.agg4 = Aggregator(reduce_dim, [32, 56, 64])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 4 8 16 32 64 global\n",
    "        f16 = self.agg16(x[2], x[3:])\n",
    "        f4 = self.agg4(x[0], [x[1], f16])\n",
    "        return f4, f16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 225, 400])\n",
      "torch.Size([1, 56, 112, 200])\n",
      "torch.Size([1, 160, 56, 100])\n",
      "torch.Size([1, 448, 28, 50])\n",
      "torch.Size([1, 448, 14, 25])\n",
      "torch.Size([1, 448, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "fh, fw = 900, 1600\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "for i, ch in enumerate([32, 56, 160, 448, 448]):\n",
    "    h = int(fh/2**(i+2))\n",
    "    w = int(fw/2**(i+2))\n",
    "    inputs.append(torch.randn((1, ch, h, w)).to(device))\n",
    "\n",
    "inputs.append(torch.randn((1, 448, 1, 1)).to(device))\n",
    "\n",
    "for input in inputs:\n",
    "    print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 225, 400])\n",
      "torch.Size([1, 64, 55, 99])\n"
     ]
    }
   ],
   "source": [
    "aggonce = AggOnce().to(device)\n",
    "f4, f32 = aggonce(inputs)\n",
    "print(f4.shape)\n",
    "print(f32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 225, 400])\n",
      "torch.Size([1, 64, 56, 100])\n"
     ]
    }
   ],
   "source": [
    "aggtwice = AggTwice().to(device)\n",
    "f4, f32 = aggtwice(inputs)\n",
    "print(f4.shape)\n",
    "print(f32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time: 2.73 ms  365.93 fps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "# aggtwice.to(device)\n",
    "# aggonce.to(device)\n",
    "\n",
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 1000\n",
    "\n",
    "timings=np.zeros((repetitions,1))\n",
    "# bbs=np.zeros((repetitions,1))\n",
    "# c1s, c2s = np.zeros((repetitions,1)), np.zeros((repetitions,1))\n",
    "# dec = np.zeros((repetitions,1))\n",
    "\n",
    "#GPU-WARM-UP\n",
    "for _ in range(10):\n",
    "    # _ = aggtwice(inputs)\n",
    "    _ = aggonce(inputs)\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "\n",
    "        starter.record()\n",
    "        # _ = aggtwice(inputs)\n",
    "        _ = aggonce(inputs)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()\n",
    "        time = starter.elapsed_time(ender)\n",
    "        timings[rep] = time\n",
    "\n",
    "avg_time = np.sum(timings) / repetitions\n",
    "\n",
    "print(f'inference time: {avg_time:.2f} ms  {1000/avg_time:.2f} fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggtwice: inference time: 2.16 ms  463.39 fps\n",
    "aggonce : inference time: 2.76 ms  362.67 fps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceAndCombine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReduceAndCombine, self).__init__()\n",
    "\n",
    "        self.reduceM = nn.AdaptiveAvgPool2d((16, 16))# 128x128을 16x16으로 줄이기\n",
    "        self.reduceV = nn.AdaptiveAvgPool2d((16, 16))# 128x128을 16x16으로 줄이기\n",
    "\n",
    "        self.tfM2V = nn.TransformerDecoderLayer(d_model=64, nhead=8, batch_first=True)\n",
    "        self.tfV2M = nn.TransformerDecoderLayer(d_model=64, nhead=8, batch_first=True)\n",
    "\n",
    "    def forward(self, fromVoxel, fromMatching):\n",
    "        \n",
    "        recudedM = self.reduceM(fromMatching).reshape(1, 64, -1)\n",
    "        recudedV = self.reduceV(fromVoxel).reshape(1, 64, -1)\n",
    "\n",
    "        recudedM = recudedM + self.tfM2V(recudedV.permute((0,2,1)), recudedV.permute((0,2,1))).reshape(1, 64, 256)\n",
    "        recudedV = recudedV + self.tfM2V(recudedV.permute((0,2,1)), recudedV.permute((0,2,1))).reshape(1, 64, 256)\n",
    "        \n",
    "        return recudedV, recudedM\n",
    "\n",
    "\n",
    "from timm.models.swin_transformer import SwinTransformerBlock\n",
    "\n",
    "\n",
    "class Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combine, self).__init__()\n",
    "\n",
    "        # um_heads=4, head_dim=None, window_size=7, shift_size=0,\n",
    "        #     mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n",
    "        #     act_layer=nn.GELU, norm_layer=nn.LayerNorm\n",
    "        \n",
    "        self.tfM2V = SwinTransformerBlock(dim=64, input_resolution=(128, 128), window_size=8)\n",
    "        self.tfV2M = SwinTransformerBlock(dim=64, input_resolution=(128, 128), window_size=8)\n",
    "\n",
    "    def forward(self, fromVoxel, fromMatching):\n",
    "        \n",
    "        recudedM = fromMatching.reshape(1, 64, -1)\n",
    "        recudedV = fromVoxel.reshape(1, 64, -1)\n",
    "\n",
    "        recudedM = recudedM + self.tfM2V(recudedM.permute((0,2,1))).permute(0, 2, 1)\n",
    "        recudedV = recudedV + self.tfM2V(recudedV.permute((0,2,1))).permute(0, 2, 1)\n",
    "        \n",
    "        return recudedV, recudedM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "inputs = torch.randn((1, 64, 128, 128)).to(device)\n",
    "\n",
    "RAC = ReduceAndCombine().to(device)\n",
    "C = Combine().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, out2 = RAC(inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16384, 64])\n"
     ]
    }
   ],
   "source": [
    "out1, out2 = C(inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time: 2.35 ms  424.68 fps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "# aggtwice.to(device)\n",
    "# aggonce.to(device)\n",
    "\n",
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 1000\n",
    "\n",
    "timings=np.zeros((repetitions,1))\n",
    "# bbs=np.zeros((repetitions,1))\n",
    "# c1s, c2s = np.zeros((repetitions,1)), np.zeros((repetitions,1))\n",
    "# dec = np.zeros((repetitions,1))\n",
    "\n",
    "#GPU-WARM-UP\n",
    "for _ in range(10):\n",
    "    # RAC(inputs, inputs)\n",
    "    out1, out2 = C(inputs, inputs)\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "\n",
    "        starter.record()\n",
    "        # RAC(inputs, inputs)\n",
    "        out1, out2 = C(inputs, inputs)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()\n",
    "        time = starter.elapsed_time(ender)\n",
    "        timings[rep] = time\n",
    "\n",
    "avg_time = np.sum(timings) / repetitions\n",
    "\n",
    "print(f'inference time: {avg_time:.2f} ms  {1000/avg_time:.2f} fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduce And Combine: inference time: 2.37 ms  422.65 fps\n",
    "Combine: inference time: 2.35 ms  424.68 fps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
