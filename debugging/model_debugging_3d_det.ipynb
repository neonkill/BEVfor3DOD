{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hydra\n",
    "from typing import Optional\n",
    "from collections.abc import Callable\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from data_module.lightning_data_module import DataModule\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "\n",
    "from model_module.lightining_model_module import ModelModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "\n",
    "    cfg.loader.batch_size = 1\n",
    "\n",
    "    if 'split' not in cfg:\n",
    "        cfg.split = 'val'\n",
    "\n",
    "    if 'shuffle' not in cfg:\n",
    "        cfg.shuffle = False\n",
    "        \n",
    "def setup_config(cfg: DictConfig, override: Optional[Callable] = None):\n",
    "\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    OmegaConf.resolve(cfg)\n",
    "    OmegaConf.set_struct(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# *  config setup  * #\n",
    "CONFIG_PATH = '/ws/CV_For_Autonomous_Driving/config'\n",
    "\n",
    "with initialize_config_dir(config_dir=CONFIG_PATH):\n",
    "    cfg = compose(config_name='default_config_debug.yaml')\n",
    "    \n",
    "setup_config(cfg, setup)\n",
    "\n",
    "# dataset list 만드는 test\n",
    "DM = DataModule('nuscenes_generated', cfg.data, cfg.loader)\n",
    "val_dataloader = DM.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 08:51:02,006 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-12 08:51:02,016 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([128, 256, 4, 4]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,017 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,018 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,018 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([128, 512, 2, 2]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,019 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,019 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,020 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([1024, 128, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,021 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,021 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,023 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([2048, 128, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,023 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,024 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,033 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2023-01-12 08:51:02,034 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2023-01-12 08:51:02,034 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2023-01-12 08:51:02,147 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2023-01-12 08:51:02,328 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "2023-01-12 08:51:02,446 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,448 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,451 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,453 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,455 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,458 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2023-01-12 08:51:02,462 - mmcv - INFO - \n",
      "conv1.weight - torch.Size([160, 80, 7, 7]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,463 - mmcv - INFO - \n",
      "bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,464 - mmcv - INFO - \n",
      "bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,464 - mmcv - INFO - \n",
      "layer1.0.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,465 - mmcv - INFO - \n",
      "layer1.0.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,465 - mmcv - INFO - \n",
      "layer1.0.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,466 - mmcv - INFO - \n",
      "layer1.0.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,466 - mmcv - INFO - \n",
      "layer1.0.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,467 - mmcv - INFO - \n",
      "layer1.0.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,467 - mmcv - INFO - \n",
      "layer1.1.conv1.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,468 - mmcv - INFO - \n",
      "layer1.1.bn1.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,468 - mmcv - INFO - \n",
      "layer1.1.bn1.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,469 - mmcv - INFO - \n",
      "layer1.1.conv2.weight - torch.Size([160, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,470 - mmcv - INFO - \n",
      "layer1.1.bn2.weight - torch.Size([160]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,470 - mmcv - INFO - \n",
      "layer1.1.bn2.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,471 - mmcv - INFO - \n",
      "layer2.0.conv1.weight - torch.Size([320, 160, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,471 - mmcv - INFO - \n",
      "layer2.0.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,472 - mmcv - INFO - \n",
      "layer2.0.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,472 - mmcv - INFO - \n",
      "layer2.0.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,472 - mmcv - INFO - \n",
      "layer2.0.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,473 - mmcv - INFO - \n",
      "layer2.0.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,473 - mmcv - INFO - \n",
      "layer2.0.downsample.0.weight - torch.Size([320, 160, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,474 - mmcv - INFO - \n",
      "layer2.0.downsample.1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,474 - mmcv - INFO - \n",
      "layer2.0.downsample.1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,475 - mmcv - INFO - \n",
      "layer2.1.conv1.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,475 - mmcv - INFO - \n",
      "layer2.1.bn1.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,476 - mmcv - INFO - \n",
      "layer2.1.bn1.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,476 - mmcv - INFO - \n",
      "layer2.1.conv2.weight - torch.Size([320, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,477 - mmcv - INFO - \n",
      "layer2.1.bn2.weight - torch.Size([320]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,477 - mmcv - INFO - \n",
      "layer2.1.bn2.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,478 - mmcv - INFO - \n",
      "layer3.0.conv1.weight - torch.Size([640, 320, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,478 - mmcv - INFO - \n",
      "layer3.0.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,479 - mmcv - INFO - \n",
      "layer3.0.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,479 - mmcv - INFO - \n",
      "layer3.0.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,480 - mmcv - INFO - \n",
      "layer3.0.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,480 - mmcv - INFO - \n",
      "layer3.0.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,481 - mmcv - INFO - \n",
      "layer3.0.downsample.0.weight - torch.Size([640, 320, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,481 - mmcv - INFO - \n",
      "layer3.0.downsample.1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,482 - mmcv - INFO - \n",
      "layer3.0.downsample.1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,482 - mmcv - INFO - \n",
      "layer3.1.conv1.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,483 - mmcv - INFO - \n",
      "layer3.1.bn1.weight - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,483 - mmcv - INFO - \n",
      "layer3.1.bn1.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,484 - mmcv - INFO - \n",
      "layer3.1.conv2.weight - torch.Size([640, 640, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,484 - mmcv - INFO - \n",
      "layer3.1.bn2.weight - torch.Size([640]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,485 - mmcv - INFO - \n",
      "layer3.1.bn2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of ResNet  \n",
      " \n",
      "2023-01-12 08:51:02,513 - mmcv - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
      "2023-01-12 08:51:02,535 - mmcv - INFO - \n",
      "deblocks.0.0.weight - torch.Size([80, 64, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,536 - mmcv - INFO - \n",
      "deblocks.0.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,537 - mmcv - INFO - \n",
      "deblocks.0.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,537 - mmcv - INFO - \n",
      "deblocks.1.0.weight - torch.Size([160, 64, 2, 2]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,538 - mmcv - INFO - \n",
      "deblocks.1.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,538 - mmcv - INFO - \n",
      "deblocks.1.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,539 - mmcv - INFO - \n",
      "deblocks.2.0.weight - torch.Size([320, 64, 4, 4]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,539 - mmcv - INFO - \n",
      "deblocks.2.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,540 - mmcv - INFO - \n",
      "deblocks.2.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,540 - mmcv - INFO - \n",
      "deblocks.3.0.weight - torch.Size([640, 64, 8, 8]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-01-12 08:51:02,541 - mmcv - INFO - \n",
      "deblocks.3.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n",
      "2023-01-12 08:51:02,541 - mmcv - INFO - \n",
      "deblocks.3.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of SECONDFPN  \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelModule(\n",
       "  (fullmodel): BaseBEVDepth(\n",
       "    (backbone): BaseLSSFPN(\n",
       "      (img_backbone): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): ResLayer(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): ResLayer(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): ResLayer(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): ResLayer(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "      (img_neck): SECONDFPN(\n",
       "        (deblocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): ConvTranspose2d(2048, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
       "      (depth_net): DepthNet(\n",
       "        (reduce_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (context_conv): Conv2d(512, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm1d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (depth_mlp): Mlp(\n",
       "          (fc1): Linear(in_features=27, out_features=512, bias=True)\n",
       "          (act): ReLU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (depth_se): SELayer(\n",
       "          (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU()\n",
       "          (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (context_mlp): Mlp(\n",
       "          (fc1): Linear(in_features=27, out_features=512, bias=True)\n",
       "          (act): ReLU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (context_se): SELayer(\n",
       "          (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU()\n",
       "          (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): ASPP(\n",
       "            (aspp1): _ASPPModule(\n",
       "              (atrous_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (aspp2): _ASPPModule(\n",
       "              (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (aspp3): _ASPPModule(\n",
       "              (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (aspp4): _ASPPModule(\n",
       "              (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (global_avg_pool): Sequential(\n",
       "              (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "              (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): ReLU()\n",
       "            )\n",
       "            (conv1): Conv2d(2560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (4): DeformConv2dPack(in_channels=512,\n",
       "          out_channels=512,\n",
       "          kernel_size=(3, 3),\n",
       "          stride=(1, 1),\n",
       "          padding=(1, 1),\n",
       "          dilation=(1, 1),\n",
       "          groups=4,\n",
       "          deform_groups=1,\n",
       "          bias=False)\n",
       "          (5): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): BEVDepthHead(\n",
       "      (loss_cls): GaussianFocalLoss()\n",
       "      (loss_bbox): L1Loss()\n",
       "      (shared_conv): ConvModule(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (task_heads): ModuleList(\n",
       "        (0): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "        (1): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "        (2): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "        (3): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "        (4): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "        (5): SeparateHead(\n",
       "          (reg): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (height): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (dim): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (rot): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (vel): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (heatmap): Sequential(\n",
       "            (0): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activate): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "      )\n",
       "      (trunk): ResNet(\n",
       "        (conv1): Conv2d(80, 160, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (layer1): ResLayer(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "        )\n",
       "        (layer2): ResLayer(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "        )\n",
       "        (layer3): ResLayer(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
       "        )\n",
       "      )\n",
       "      init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "      (neck): SECONDFPN(\n",
       "        (deblocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): ConvTranspose2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): ConvTranspose2d(160, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): ConvTranspose2d(320, 64, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): ConvTranspose2d(640, 64, kernel_size=(8, 8), stride=(8, 8), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MM = ModelModule()\n",
    "MM.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/ws/CV_For_Autonomous_Driving/model_module/model/detection/bev_depth_head.py:367: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  num = torch.clamp(reduce_mean(target_box.new_tensor(num)),\n"
     ]
    }
   ],
   "source": [
    "det_loss, depth_loss = MM.shared_step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "pred, depth = MM(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 1, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 2, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 2, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 1, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 2, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "reg torch.Size([8, 2, 128, 128])\n",
      "height torch.Size([8, 1, 128, 128])\n",
      "dim torch.Size([8, 3, 128, 128])\n",
      "rot torch.Size([8, 2, 128, 128])\n",
      "vel torch.Size([8, 2, 128, 128])\n",
      "heatmap torch.Size([8, 2, 128, 128])\n",
      "dict_keys(['reg', 'height', 'dim', 'rot', 'vel', 'heatmap'])\n",
      "torch.Size([48, 112, 16, 44])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "model에 클래스 별로 head가 있음\n",
    "클래스는 lightning_model_module.py에 있음\n",
    "\n",
    "샘플이 별로 없는 클래스들은 하나로 묶어서 준다..\n",
    "\n",
    "pred: 각 head 별 6개의 dict\n",
    "    reg torch.Size([8, 2, 128, 128])        # offset..\n",
    "    height torch.Size([8, 1, 128, 128])     # BEV height\n",
    "    dim torch.Size([8, 3, 128, 128])        # 3D bbox w, h, l\n",
    "    rot torch.Size([8, 2, 128, 128])        # sin(alpha), cos(alpha)\n",
    "    vel torch.Size([8, 2, 128, 128])        # vx, vy\n",
    "    heatmap torch.Size([8, 1, 128, 128])    # center confidence\n",
    "'''\n",
    "\n",
    "print(len(pred))\n",
    "for cam in range(6):\n",
    "    for k, v in pred[cam][0].items():\n",
    "        print(k, v.shape)\n",
    "    print(pred[cam][0].keys())\n",
    "# print(pred[0].shape)\n",
    "print(depth.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
